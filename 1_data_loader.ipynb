{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamed-ssafini/Transformers/blob/main/1_data_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CMWMOaDg-ZBv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Use CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oenVmIBQnCKf",
        "outputId": "e3a75d3b-592c-4c91-ce15-5525c5324b6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL of tiny-shakespeare.txt hosted online\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "\n",
        "# Make a GET request to fetch the file content\n",
        "response = requests.get(url)\n",
        "\n",
        "# Raise an error if the request was unsuccessful\n",
        "response.raise_for_status()\n",
        "\n",
        "# Get the text content of the file\n",
        "text = response.text\n",
        "\n",
        "# Now the variable 'text' holds the contents of 'tiny-shakespeare.txt'\n",
        "print(text[:500])  # printing the first 500 characters to verify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5YgHb8vnCd4",
        "outputId": "0a4a6cea-4be3-4c45-c0b7-1589d6dce02c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0:500])"
      ],
      "metadata": {
        "id": "0j0IWXBJm_Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IwwOe-tJ-xcE",
        "outputId": "6adfd587-9abd-46aa-b08f-7aad74212272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text[0:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ap_Ixr0M-0Yv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class CharTokenizer:\n",
        "  def __init__(self, vocabulary):\n",
        "    self.id_for_char = {chr: id for id, chr in enumerate(vocabulary)}\n",
        "    self.char_for_id = {id: chr for id, chr in enumerate(vocabulary)}\n",
        "\n",
        "  @staticmethod\n",
        "  def train_from_text(text):\n",
        "    vocabulary = set(text)\n",
        "    return CharTokenizer(vocabulary)\n",
        "\n",
        "  def encode(self, text):\n",
        "    ids = []\n",
        "    for chr in text:\n",
        "      ids.append(self.id_for_char[chr])\n",
        "    return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "  def decode(self, ids):\n",
        "    chars = []\n",
        "    for id in ids.tolist():\n",
        "      chars.append(self.char_for_id[id])\n",
        "    return ''.join(chars)\n",
        "\n",
        "  def vocabulary_size(self):\n",
        "    return len(self.id_for_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T3q9Dj3l-2Ja"
      },
      "outputs": [],
      "source": [
        "tokenizer = CharTokenizer.train_from_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb1zImZr-4mY",
        "outputId": "f6c1e64a-bc97-409c-b83f-82afd17c3bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([24, 38, 63, 63, 13,  6, 14, 13, 17, 63, 53])\n",
            "Hello world\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"Hello world\"))\n",
        "print(tokenizer.decode(tokenizer.encode(\"Hello world\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlTEiIqs-7Uz",
        "outputId": "af4a80c2-7c41-424a-da21-c300292d123c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 65\n"
          ]
        }
      ],
      "source": [
        "print(f\"Vocabulary size: {tokenizer.vocabulary_size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7Qal76ig-94U"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IndexesDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = data\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        # Ensure all sequences generated are complete by reducing length\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, pos):\n",
        "        assert pos < len(self.data) - self.block_size\n",
        "\n",
        "        x = self.data[pos:pos + self.block_size]\n",
        "        y = self.data[pos + 1:pos + 1 + self.block_size]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oPPfQ5n1_BuV"
      },
      "outputs": [],
      "source": [
        "tokenized_text = tokenizer.encode(text)\n",
        "dataset = IndexesDataset(tokenized_text, 64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = dataset[0]"
      ],
      "metadata": {
        "id": "By1LKb_2veLw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTjH3qRUv4WB",
        "outputId": "59d5e9fa-0f99-4d3e-db2e-f1b2677c7baa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3, 29, 17, 19, 51,  6, 60, 29, 51, 29, 64, 38, 33, 48,  4, 43, 38, 54,\n",
              "        13, 17, 38,  6, 14, 38,  6, 39, 17, 13,  8, 38, 38, 53,  6,  2, 33, 35,\n",
              "         6, 54, 61, 17, 51, 30, 38, 17, 36,  6, 30, 38,  2, 17,  6, 16, 38,  6,\n",
              "        19, 39, 38,  2, 25, 62,  4,  4, 57, 63])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY64Wkebv7ee",
        "outputId": "0fd17686-98ad-4874-9479-8fc8464c505f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([29, 17, 19, 51,  6, 60, 29, 51, 29, 64, 38, 33, 48,  4, 43, 38, 54, 13,\n",
              "        17, 38,  6, 14, 38,  6, 39, 17, 13,  8, 38, 38, 53,  6,  2, 33, 35,  6,\n",
              "        54, 61, 17, 51, 30, 38, 17, 36,  6, 30, 38,  2, 17,  6, 16, 38,  6, 19,\n",
              "        39, 38,  2, 25, 62,  4,  4, 57, 63, 63])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A7nfACWb0eNc",
        "outputId": "e23b1325-8901-4055-a8ba-4702638f4847"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S1QQH7fl00kD",
        "outputId": "5af643e3-5bb7-4eb5-f48b-0f604daa0647"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pU5xPNPN_RSQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "sampler = RandomSampler(dataset, replacement=True)\n",
        "dataloader = DataLoader(dataset, batch_size=2, sampler=sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cmoIkxKP_gBD"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKvdaDFb_mxv",
        "outputId": "f0411a3c-1396-493c-c392-e5ee7c057623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[17,  6, 19, 30, 13, 61, 63, 53,  6, 30, 38, 17,  6, 10, 13, 53, 35,  6,\n",
              "         19, 51, 13, 13, 39,  4, 58, 13,  6, 19, 61,  8, 30,  6,  2, 10, 30, 13,\n",
              "         17, 17, 41, 53,  6, 39, 13, 63, 63, 61, 51, 29, 13, 33, 62,  4, 58, 30,\n",
              "         38, 33, 36,  6, 49, 19,  2, 10, 38, 63],\n",
              "        [35,  6, 30, 13, 63, 35,  6, 19, 29, 17, 36,  6, 33, 13, 33, 38,  6, 10,\n",
              "         38, 51, 51, 38, 17,  6, 25, 33, 13, 14, 19,  6, 51, 30,  2, 33,  6, 35,\n",
              "         13, 61,  4, 24, 13, 14,  6, 49,  6, 30,  2, 12, 38,  6, 38, 12, 38, 17,\n",
              "          6, 63, 13, 12, 38, 53,  6, 51, 30, 38]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mRYTdaFs_nrH",
        "outputId": "3dfd0093-7adb-496a-8d3c-5f25777b2a2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"r should her body stoop\\nTo such abhorr'd pollution.\\nThen, Isabel\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer.decode(x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7z-wrmxL_ucH",
        "outputId": "c86795e4-1716-4e3f-e1b3-28e07c4b7336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" should her body stoop\\nTo such abhorr'd pollution.\\nThen, Isabel,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.decode(y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyqnpXW7_w__"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}